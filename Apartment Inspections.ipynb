{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23401edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today() ) )\n",
    "\n",
    "print (\"Import packages\")\n",
    "#pip install cx_Oracle\n",
    "#pip install sqlalcheny\n",
    "#Download Oracle- https://www.oracle.com/database/technologies/instant-client/downloads.html\n",
    "#Connect to cx_Oracle and import packages\n",
    "import cx_Oracle\n",
    "\n",
    "#create path to downloaded oracle files and initiate\n",
    "cx_Oracle.init_oracle_client(lib_dir=r\"C:\\Oracle\\instantclient_21_9\")\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.schema import CreateIndex\n",
    "from sqlalchemy import Table, Column, Integer, Numeric,String, ForeignKey\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import insert\n",
    "metadata= MetaData()\n",
    "\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2781853",
   "metadata": {},
   "source": [
    "### Import Labor Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73000753",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d395e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print (\"Import labor transactions\")\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "labtrans_query = \"\"\"\n",
    "\n",
    "select labtrans.LABORCODE,\n",
    "       labtrans.ENTERDATE,\n",
    "       labtrans.REFWO,\n",
    "       labtrans.TRANSTYPE,\n",
    "       labtrans.startdatetime,\n",
    "       labtrans.finishdatetime,\n",
    "       labtrans.location\n",
    "\n",
    "       \n",
    "from Maximo.labtrans labtrans\n",
    "--WHERE (labtrans.startdatetime >= '01-JAN-2023' AND labtrans.startdatetime <= '1-SEP-2023') AND labtrans.transtype = 'INSPECTION'\n",
    "--WHERE (labtrans.startdatetime >= '01-JAN-2023' AND labtrans.startdatetime <= '1-SEP-2023') AND (labtrans.transtype = 'INSPECTION' OR labtrans.transtype = 'NOBLDGACCESS' OR labtrans.transtype = 'RESREFUSED' OR labtrans.transtype ='RESNOTHOME')\n",
    "WHERE (labtrans.startdatetime >= '01-JAN-2022' AND labtrans.startdatetime <= '31-DEC-2022') \n",
    "\n",
    "--WHERE (labtrans.startdatetime >= '01-JAN-2022' AND labtrans.startdatetime <= '31-DEC-2022') AND (labtrans.transtype = 'WORKWITHSEQ' OR labtrans.transtype = 'WORK')\n",
    "--WHERE TRUNC(labtrans.enterdate) >= sysdate - interval '1' year  AND (labtrans.transtype = 'WORKWITHSEQ' OR labtrans.transtype = 'WORK' OR labtrans.transtype = 'NOBLDGACCESS' OR labtrans.transtype = 'RESREFUSED' OR labtrans.transtype ='RESNOTHOME' OR labtrans.transtype ='UNFOUNDED' )\n",
    "\n",
    "\"\"\"\n",
    "#(labtrans.enterdate >= '01-JAN-2022')\n",
    "\n",
    "#WHERE TRUNC(xrf_det.entrydate) >= sysdate - interval '1' year AND xrf_det.finalclassification = 'Positive' AND xrf_det.side != 'Calibrate' AND xrf_det.side != 'CALIBRATE'\n",
    "#(labtrans.enterdate >= '12-JAN-2023')\n",
    "#(labtrans.enterdate >= '01-JAN-2022' AND labtrans.enterdate <= '1-MAR-2022')\n",
    "\n",
    "\n",
    "\n",
    "dl = pd.read_sql_query(labtrans_query, engine)\n",
    "\n",
    "print (len(dl))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff08332",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Reading labor transactions...\")\n",
    "path = \"\"\n",
    "\n",
    "dl1 = pd.read_csv(path + \"Labor Transactions 2022.csv\")\n",
    "dl2 = pd.read_csv(path + \"Labor Transactions 2023.csv\")\n",
    "\n",
    "frames = [dl1, dl2]\n",
    "\n",
    "dl = pd.concat(frames)\n",
    "dl = dl.reset_index(drop=True)\n",
    "\n",
    "print (len(dl))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.to_csv(path + \"Labor Transactions 2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc9ab4",
   "metadata": {},
   "source": [
    "### Import Work Orders to get wonum to subset labor trans and Insert Other Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda32c5",
   "metadata": {},
   "source": [
    "### 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "print (\"Import work orders\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "workorder_query = \"\"\"\n",
    "\n",
    "select max_wo.worktype,\n",
    "       max_wo.problemcode,\n",
    "       max_wo.failurecode,\n",
    "       max_wo.wonum,\n",
    "       max_wo.parent,\n",
    "       TRUNC(max_wo.reportdate) AS report_date,\n",
    "       max_wo.status,\n",
    "       TRUNC(max_wo.statusdate) AS status_date,\n",
    "       max_wo.location,\n",
    "       max_wo.haschildren,\n",
    "       max_wo.OWNERGROUP,\n",
    "       max_wo.ACTSTART,\n",
    "       max_wo.ACTFINISH,\n",
    "       max_wo.ZZCRAFT,\n",
    "       max_wo.JPNUM\n",
    "       \n",
    "from Maximo.workorder max_wo\n",
    "\n",
    "--WHERE TRUNC(max_wo.reportdate) >= sysdate - interval '1' year AND max_wo.status = 'CLOSE' AND max_wo.failurecode = 'EXTERMINATION' AND max_wo.worktype = 'CM' \n",
    "\n",
    "WHERE (max_wo.actstart >= '01-JAN-2023' AND max_wo.actstart <= '01-SEP-2023') AND max_wo.status = 'CLOSE' AND max_wo.zzcraft = 'MAINT' AND max_wo.jpnum = 'INSAPT'\n",
    "--WHERE (max_wo.reportdate >= '01-NOV-2021' AND max_wo.reportdate <= '30-NOV-2021') AND max_wo.status = 'CLOSE' AND max_wo.zzcraft = 'MAINT' AND max_wo.jpnum = 'INSAPT'\n",
    "--WHERE (max_wo.reportdate >= '01-NOV-2021' AND max_wo.reportdate <= '30-NOV-2021') AND max_wo.jpnum = 'INSAPT'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#(max_wo.reportdate >= '01-JAN-2022')\n",
    "#(max_wo.reportdate >= '01-JAN-2022' AND max_wo.reportdate <= '1-MAR-2022')\n",
    "\n",
    "df = pd.read_sql_query(workorder_query, engine)\n",
    "\n",
    "#print (len(df))\n",
    "#df = df[pd.notnull(df['actstart'])]\n",
    "#print (len(df))\n",
    "\n",
    "\n",
    "#print (\"Subset for closed work orders\")\n",
    "#print (len(df))\n",
    "#df = df[df[\"status\"] == \"CLOSE\"]\n",
    "#df = df[df[\"status\"] == \"APPR\"]\n",
    "\n",
    "#subsetlist = [\"CLOSE\", \"APPR\"]\n",
    "\n",
    "#df = df[df['status'].isin(subsetlist)].reset_index(drop=True)\n",
    "\n",
    "#print (len(df))\n",
    "#df = df[df[\"jpnum\"] == 'M10353']\n",
    "#df = df[df[\"zzcraft\"] == 'EXTERMIN']\n",
    "#print (len(df))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "#print (test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d892fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Reading work orders...\")\n",
    "df1 = pd.read_csv(path + \"Work Orders 2022.csv\")\n",
    "df2 = pd.read_csv(path + \"Work Orders 2023.csv\")\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print (len(df))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aff42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(path + \"Work Orders 2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df[df[\"jpnum\"] == 'INSAPT']\n",
    "#print (len(df))\n",
    "#print (len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae09f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"jpnum\"] = df[\"jpnum\"].astype(str)\n",
    "#jpnum = sorted(list(set(df[\"jpnum\"].tolist() )))\n",
    "#jpnum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d6170",
   "metadata": {},
   "source": [
    "Subset Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wonum\"] = df[\"wonum\"].astype(str).map(str.strip)\n",
    "dl['refwo'] = dl['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "dflist = df[\"wonum\"].tolist()\n",
    "\n",
    "dllist = dl['refwo'].tolist()\n",
    "\n",
    "x = list(set(dflist).intersection(dllist))\n",
    "\n",
    "print (len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf031ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Subset Labor Transactions\")\n",
    "\n",
    "df[\"wonum\"] = df[\"wonum\"].astype(str).map(str.strip)\n",
    "dl['refwo'] = dl['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "dflist = df[\"wonum\"].tolist()\n",
    "\n",
    "dllist = dl['refwo'].tolist()\n",
    "\n",
    "x = list(set(dflist).intersection(dllist))\n",
    "\n",
    "print (len(dl))\n",
    "\n",
    "dl2 = dl[dl['refwo'].isin(dflist)].reset_index(drop=True)\n",
    "\n",
    "print (len(dl2))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27018ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transtype = set(dl2[\"transtype\"].tolist() )\n",
    "\n",
    "transtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35073521",
   "metadata": {},
   "source": [
    "### Insert Work Order Fields into Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "dftypes = [\"ownergroup\", \"zzcraft\"]\n",
    "\n",
    "for d in dftypes:\n",
    "    dfDic = df.set_index('wonum')[d].to_dict()\n",
    "    dl2[d] = dl2[\"refwo\"].map(dfDic)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e215d3",
   "metadata": {},
   "source": [
    "### Import Person Data and Merge with Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Import person data\")\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "person_query = \"\"\"\n",
    "\n",
    "select *  \n",
    "       \n",
    "from Maximo.person \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#WHERE TRUNC(xrf_det.entrydate) >= sysdate - interval '1' year AND xrf_det.finalclassification = 'Positive' AND xrf_det.side != 'Calibrate' AND xrf_det.side != 'CALIBRATE'\n",
    "\n",
    "\n",
    "dp = pd.read_sql_query(person_query, engine)\n",
    "dp = dp[[\"personid\", \"status\", \"displayname\",\"firstname\",\"lastname\",\"department\",\"title\", \"zzhrtitle\", \"hiredate\", \"terminationdate\"]]\n",
    "dp[\"personid\"] = dp[\"personid\"].astype(str).map(str.strip)\n",
    "dp = dp.rename(columns={'personid': 'laborcode'})\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "dl2[\"laborcode\"] = dl2[\"laborcode\"].astype(str).map(str.strip)\n",
    "print (len(dl2))\n",
    "dl2 = pd.merge(dl2, dp, how='left', on=['laborcode'])\n",
    "print (len(dl2))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl2.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#people = sorted(list(set(dl2[\"displayname\"].tolist() ) ))\n",
    "#print (len(people))\n",
    "#dp2 = dp[dp['displayname'].isin(people)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp2.to_csv(path + \"Exterminators from Person Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transtype = set(dl2[\"transtype\"].tolist() )\n",
    "transtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5bea7",
   "metadata": {},
   "source": [
    "### Get IPM Inspection Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264982ad",
   "metadata": {},
   "source": [
    "### Import Questions Only  2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "\n",
    "\n",
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, wt.actstart,\n",
    "wt.jpnum, lt.craft,\n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  (lt.startdatetime >= '01-SEP-2023' AND lt.startdatetime <= '30-SEP-2023')\n",
    "\n",
    "and wt.status = 'CLOSE'\n",
    "and lt.transtype = 'INSPECTION'\n",
    "and lt.craft = 'MAINT'\n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#WHERE (max_wo.actstart >= '01-JAN-2022' AND max_wo.actstart <= '31-DEC-2022') AND max_wo.status = 'CLOSE' \n",
    "#AND max_wo.zzcraft = 'MAINT' AND max_wo.jpnum = 'INSAPT'\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "print (len(dq))\n",
    "\n",
    "#path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "#dq.to_csv(path + \"Labor_Transactions_jan-mar_2022.csv\", index=False)\n",
    "\n",
    "print (\"Export\")\n",
    "dq.to_csv(path + \"Questions Sep 2023.csv\")\n",
    "\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "jpnum = sorted(list(set(dq[\"jpnum\"].tolist() )))\n",
    "print (jpnum)\n",
    "\n",
    "wonum1 = sorted(list(set(dq[\"wonum1\"].tolist() )))\n",
    "print (\"wonum1\", len(wonum1))\n",
    "\n",
    "wonum2 = sorted(list(set(dq[\"wonum2\"].tolist() )))\n",
    "print (\"wonum2\", len(wonum2))\n",
    "\n",
    "\n",
    "transtype = sorted(list(set(dq[\"transtype\"].tolist() )))\n",
    "print (len(transtype))\n",
    "\n",
    "\n",
    "craft = sorted(list(set(dq[\"craft\"].tolist() )))\n",
    "print (len(craft))\n",
    "\n",
    "\n",
    "description3 = sorted(list(set(dq2[\"description3\"].tolist() )))\n",
    "print (len(description3))\n",
    "description3\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef697c",
   "metadata": {},
   "source": [
    "### Concatinate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db611f",
   "metadata": {},
   "source": [
    "Import Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "dques = pd.read_csv(path + \"Questions Prelim.csv\", encoding = \"utf-8\")\n",
    "desc = sorted(list(set(dques[\"Description\"].tolist() )))\n",
    "\n",
    "dques[\"Description\"] = dques[\"Description\"].astype(str).map(str.strip).map(str.upper)\n",
    "dques[\"Question\"] = dques[\"Question\"].astype(str).map(str.strip).map(str.upper)\n",
    "\n",
    "dques[\"Question Location\"] = dques[\"Question\"] + \" \" + dques[\"Description\"]\n",
    "\n",
    "dquesList = sorted(list(set(dques[\"Question Location\"].tolist() )))\n",
    "\n",
    "dquesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012796a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "dl2refwoList = sorted(list(set(dl2[\"refwo\"].tolist() )))\n",
    "print (len(dl2refwoList))\n",
    "\n",
    "def DataClean(dq,dl2refwoList, dquesList ):\n",
    "    print (len(dq))\n",
    "    dq[\"wonum1\"] = dq[\"wonum1\"].astype(str).map(str.strip)\n",
    "    dq = dq[dq['wonum1'].isin(dl2refwoList)]\n",
    "    print (len(dq))\n",
    "\n",
    "    dq[\"description2\"] = dq[\"description2\"].astype(str).map(str.strip).map(str.upper)\n",
    "    dq[\"description3\"] = dq[\"description3\"].astype(str).map(str.strip).map(str.upper)\n",
    "\n",
    "    dq[\"Question Location\"] = dq[\"description3\"] + \" \" + dq[\"description2\"]\n",
    "\n",
    "    dq = dq[dq['Question Location'].isin(dquesList)].reset_index(drop=True)\n",
    "\n",
    "    print (len(dq))\n",
    "    \n",
    "    return dq\n",
    "\n",
    "pathq = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Apartment Inspections\\\\Question Data\\\\\"\n",
    "\n",
    "print ()\n",
    "\n",
    "dq1 = pd.read_csv(pathq + \"Questions Jan 2022.csv\", low_memory=False)\n",
    "print (\"Jan 2022\")\n",
    "dq1 = DataClean(dq1,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq2 = pd.read_csv(pathq + \"Questions Feb 2022.csv\", low_memory=False)\n",
    "print (\"Feb 2022\")\n",
    "dq2 = DataClean(dq2,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq3 = pd.read_csv(pathq + \"Questions March 2022.csv\", low_memory=False)\n",
    "print (\"March 2022\")\n",
    "dq3 = DataClean(dq3,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq4 = pd.read_csv(pathq + \"Questions April 2022.csv\",low_memory=False )\n",
    "print (\"April 2022\")\n",
    "dq4 = DataClean(dq4,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq5 = pd.read_csv(pathq + \"Questions May 2022.csv\", low_memory=False)\n",
    "print (\"May 2022\")\n",
    "dq5 = DataClean(dq5,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq6 = pd.read_csv(pathq + \"Questions June 2022.csv\", low_memory=False)\n",
    "print (\"June 2022\")\n",
    "dq6 = DataClean(dq6,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq7 = pd.read_csv(pathq + \"Questions July 2022.csv\", low_memory=False)\n",
    "print (\"July 2022\")\n",
    "dq7 = DataClean(dq7,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq8 = pd.read_csv(pathq + \"Questions August 2022.csv\", low_memory=False)\n",
    "print (\"Aug 2022\")\n",
    "dq8 = DataClean(dq8,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq9 = pd.read_csv(pathq + \"Questions Sept 2022.csv\", low_memory=False)\n",
    "print (\"Sept 2022\")\n",
    "dq9 = DataClean(dq9,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq10 = pd.read_csv(pathq + \"Questions Oct 2022.csv\", low_memory=False)\n",
    "print (\"Oct 2022\")\n",
    "dq10 = DataClean(dq10,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq11 = pd.read_csv(pathq + \"Questions Nov 2022.csv\", low_memory=False)\n",
    "print (\"Nov 2022\")\n",
    "dq11 = DataClean(dq11,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq12 = pd.read_csv(pathq + \"Questions Dec 2022.csv\", low_memory=False)\n",
    "print (\"Dec 2022\")\n",
    "dq12 = DataClean(dq12,dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "\n",
    "dq13 = pd.read_csv(pathq + \"Questions Jan 2023.csv\", low_memory=False)\n",
    "print (\"Jan 2023\")\n",
    "dq13 = DataClean(dq13, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq14 = pd.read_csv(pathq + \"Questions Feb 2023.csv\", low_memory=False)\n",
    "print (\"Feb 2023\")\n",
    "dq14 = DataClean(dq14, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq15 = pd.read_csv(pathq + \"Questions Mar 2023.csv\", low_memory=False)\n",
    "print (\"Mar 2023\")\n",
    "dq15 = DataClean(dq15, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq16 = pd.read_csv(pathq + \"Questions Apr 2023.csv\", low_memory=False)\n",
    "print (\"Apr 2023\")\n",
    "dq16 = DataClean(dq16, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq17 = pd.read_csv(pathq + \"Questions May 2023.csv\", low_memory=False)\n",
    "print (\"May 2023\")\n",
    "dq17 = DataClean(dq17, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq18 = pd.read_csv(pathq + \"Questions Jun 2023.csv\", low_memory=False)\n",
    "print (\"Jun 2023\")\n",
    "dq18 = DataClean(dq18, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq19 = pd.read_csv(pathq + \"Questions Jul 2023.csv\", low_memory=False)\n",
    "print (\"Jul 2023\")\n",
    "dq19 = DataClean(dq19, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "dq20 = pd.read_csv(pathq + \"Questions Aug 2023.csv\", low_memory=False)\n",
    "print (\"Aug 2023\")\n",
    "dq20 = DataClean(dq20, dl2refwoList, dquesList )\n",
    "print ()\n",
    "\n",
    "\n",
    "frames = [dq1, dq2, dq3, dq4, dq5,dq6, dq7, dq8, dq9, dq10, dq11, dq12, dq13, dq14, dq15, dq16, dq17, dq18, dq19, dq20 ]\n",
    "\n",
    "dq = pd.concat(frames)\n",
    "dq = dq.reset_index(drop=True)\n",
    "\n",
    "print (dq.shape)\n",
    "\n",
    "dq = dq[[\"wonum1\", \"Question Location\", \"result\"]]\n",
    "\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dq.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784bdcc",
   "metadata": {},
   "source": [
    "Subset using Work Order Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a23b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "dq[\"wonum1\"] = dq[\"wonum1\"].astype(str).map(str.strip)\n",
    "dl2['refwo'] = dl2['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "wolist = list(set(dq[\"wonum1\"].tolist()  ))\n",
    "\n",
    "print (len(dl2))\n",
    "dl3 = dl2[dl2['refwo'].isin(wolist)].reset_index(drop=True)\n",
    "print (len(dl3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba156e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "transtype = set(dl3[\"transtype\"].tolist() )\n",
    "transtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b16162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl3.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f441d",
   "metadata": {},
   "source": [
    "### Insert Qustions and Results into Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "#desc = sorted(list(set(dq[\"description3\"].tolist() ) ))\n",
    "#desc.remove('Adjacent Apartment 1')\n",
    "#desc.remove('Adjacent Apartment 2')\n",
    "#desc.remove('Adjacent Apartment 3')\n",
    "#desc.remove('Adjacent Apartment 4')\n",
    "\n",
    "\n",
    "#desc = [\"Was Resident Educational Literature issued\",\"Frass Removal\", \"HEPA Vacuum\", \n",
    "#       \"Fill holes with excluder mesh or similar product\",\"Sealing\", \"Escutcheon Plate Installation\" ]\n",
    "\n",
    "desc = list(set(dq[\"Question Location\"].tolist() ))\n",
    "\n",
    "dq2 = dq.copy()\n",
    "\n",
    "dq2[\"wonum1\"] = dq2[\"wonum1\"].astype(str).map(str.strip)\n",
    "dl3['refwo'] = dl3['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "\n",
    "for d in desc:\n",
    "    #print (d)\n",
    "    dq3 = dq2[dq2[\"Question Location\"] == d]\n",
    "    print (d)\n",
    "    print (len(dq3) )\n",
    "    #print (dq3)\n",
    "    \n",
    "    dq3Dic = dq3.set_index('wonum1')['result'].to_dict()\n",
    "\n",
    "    dl3[d] = dl3[\"refwo\"].map(dq3Dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b23c1",
   "metadata": {},
   "source": [
    "### Calculate Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "print (\"Calculate time\")\n",
    "\n",
    "dl3['startdatetime'] = pd.to_datetime(dl3['startdatetime'])\n",
    "\n",
    "dl3['finishdatetime'] = pd.to_datetime(dl3['finishdatetime'])\n",
    "\n",
    "\n",
    "#df2['Hours'] = (df2[\"actfinish\"] - df2[\"actstart\"]).dt.days\n",
    "\n",
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "dl3 = dl3.reset_index(drop=True)\n",
    "\n",
    "dl3['Seconds'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds\n",
    "dl3['Hours'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds / 3600.0\n",
    "dl3['Minutes'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds / 60.0\n",
    "dl3['Days'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.days\n",
    "\n",
    "dl3[\"Hours\"] = dl3[\"Hours\"].astype(float)\n",
    "dl3[\"Hours\"] = dl3[\"Hours\"].round(2)\n",
    "\n",
    "dl3[\"Minutes\"] = dl3[\"Minutes\"].astype(float)\n",
    "dl3[\"Minutes\"] = dl3[\"Minutes\"].round(2)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424cfeb1",
   "metadata": {},
   "source": [
    "### Merge Building and Development Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb785d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "dl3['location'] = dl3['location'].astype(str)\n",
    "\n",
    "dl3[\"TDS\"] = dl3['location'].str.split(\".\").str[0]\n",
    "\n",
    "print (\"Import nycha_org_dim\")\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "nycha_org_query = \"\"\"\n",
    "\n",
    "select *\n",
    "       \n",
    "from maximo.nycha_org_dim nychaorg\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dnycha = pd.read_sql_query(nycha_org_query, engine)\n",
    "\n",
    "subset = ['tds_num', 'borough_name', 'development_name']\n",
    "\n",
    "dnycha= dnycha[subset]\n",
    "\n",
    "\n",
    "tds = dnycha.tds_num.tolist()\n",
    "\n",
    "tdslist = []\n",
    "\n",
    "for c in tds:\n",
    "    c = str(c)\n",
    "    \n",
    "    #print (c)\n",
    "    \n",
    "    if len(c) == 1:\n",
    "        c = \"00\" + c\n",
    "        tdslist.append(c)\n",
    "    elif len(c) == 2:\n",
    "        c = \"0\" + c\n",
    "        tdslist.append(c)\n",
    "    else:\n",
    "        tdslist.append(c)\n",
    "\n",
    "\n",
    "print (len(tdslist))\n",
    "print (len(dnycha))\n",
    "\n",
    "qn = pd.DataFrame(tdslist)\n",
    "\n",
    "qn = qn.rename(columns={0: 'TDS'})\n",
    "\n",
    "dnycha = pd.concat([dnycha, qn], axis=1)\n",
    "\n",
    "print (\"Merge with labor transactions\")\n",
    "print (len(dl3))\n",
    "dl3 = pd.merge(dl3, dnycha, how='left', on=['TDS'])\n",
    "print (len(dl3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fbfda",
   "metadata": {},
   "source": [
    "### Insert Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "path2 = \"\"\n",
    "\n",
    "db = pd.read_csv(path2 + \"zzbuildings.csv\", low_memory=False)\n",
    "\n",
    "db[\"BUILDING\"] = db[\"BUILDING\"].astype(str)\n",
    "db[\"BLDGNO\"] = db[\"BLDGNO\"].astype(str)\n",
    "\n",
    "db[\"TDS\"] = db[\"BUILDING\"].str.split(\".\").str[0]\n",
    "\n",
    "#convert 1 to 01\n",
    "for i in range(0, len(db)):\n",
    "    a = db[\"BLDGNO\"][i]\n",
    "    if len(a) == 1:\n",
    "        db[\"BLDGNO\"][i] = \"0\" + db[\"BLDGNO\"][i]\n",
    "        \n",
    "    b = db[\"TDS\"][i]\n",
    "    if len(b) == 1:\n",
    "        db[\"TDS\"][i] = \"00\" + db[\"TDS\"][i]\n",
    "    if len(b) == 2:\n",
    "        db[\"TDS\"][i] = \"0\" + db[\"TDS\"][i] \n",
    "        \n",
    "\n",
    "\n",
    "db[\"Building\"] = db[\"TDS\"] + \".\" + db[\"BLDGNO\"]\n",
    "\n",
    "sitid = set(db[\"SITEID\"].tolist() )\n",
    "print(sitid)\n",
    "\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('BK', 'BROOKYN')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('BX', 'BRONX')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('QS', 'QUEENS/STATEN ISLAND')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('MN', 'MANHATTAN')\n",
    "\n",
    "db[\"ADDRESS\"] = db[\"ADDRESS\"] + \", \" + db[\"SITEID\"]\n",
    "\n",
    "\n",
    "dl3[\"Building No\"] = dl3['location'].str.split(\".\").str[1]\n",
    "\n",
    "dl3[\"TDS\"] = dl3[\"TDS\"].astype(str)\n",
    "dl3[\"Building\"] = dl3[\"TDS\"] + \".\" + dl3[\"Building No\"]\n",
    "\n",
    "\n",
    "#dictionary to insert data\n",
    "dbDic = db.set_index('Building')['ADDRESS'].to_dict()\n",
    "\n",
    "dl3[\"Building Address\"] = dl3[\"Building\"].map(dbDic)\n",
    "dl3[\"Building Address\"] = dl3[\"Building Address\"].astype(str).map(str.strip)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4d635",
   "metadata": {},
   "source": [
    "### Insert Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "path2 = \"\"\n",
    "\n",
    "dgis = pd.read_csv(path2 + \"nycha_loc_gps.csv\", low_memory=False)\n",
    "\n",
    "dgis[\"TDS_NUM\"] = dgis[\"TDS_NUM\"].astype(str)\n",
    "dgis[\"BLDG_NUM\"] = dgis[\"BLDG_NUM\"].astype(str)\n",
    "\n",
    "for i in range(0, len(dgis)):\n",
    "    a = dgis[\"BLDG_NUM\"][i]\n",
    "    if len(a) == 1:\n",
    "        dgis[\"BLDG_NUM\"][i] = \"0\" + dgis[\"BLDG_NUM\"][i]\n",
    "        \n",
    "    b = dgis[\"TDS_NUM\"][i]\n",
    "    if len(b) == 1:\n",
    "        dgis[\"TDS_NUM\"][i] = \"00\" + dgis[\"TDS_NUM\"][i]\n",
    "    if len(b) == 2:\n",
    "        dgis[\"TDS_NUM\"][i] = \"0\" + dgis[\"TDS_NUM\"][i]            \n",
    "\n",
    "dgis[\"Building\"] = dgis[\"TDS_NUM\"] + \".\" + dgis[\"BLDG_NUM\"]\n",
    "\n",
    "lat = dgis.set_index('Building')['LATITUDE'].to_dict()\n",
    "dl3[\"lat\"] = dl3[\"Building\"].map(lat)\n",
    "\n",
    "lon = dgis.set_index('Building')['LONGITUDE'].to_dict()\n",
    "dl3[\"lon\"] = dl3[\"Building\"].map(lon)\n",
    "\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8832",
   "metadata": {},
   "source": [
    "### Flag Work orders < 10 Minutes > 30 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7546fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "minutes = dl3[\"Minutes\"].tolist()\n",
    "\n",
    "\n",
    "mintues30flag = []\n",
    "mintues10flag = []\n",
    "mintues20flag = []\n",
    "#greater10minutesflag = []\n",
    "\n",
    "\n",
    "for i in range(0, len(minutes)):\n",
    "    if minutes[i] <= 30:\n",
    "        mintues30flag.append(\"Yes\")\n",
    "    else:\n",
    "        mintues30flag.append(\"No\")\n",
    "        \n",
    "        \n",
    "    if minutes[i] <= 20:\n",
    "        mintues20flag.append(\"Yes\")\n",
    "    else:\n",
    "        mintues20flag.append(\"No\")\n",
    "        \n",
    "        \n",
    "    if minutes[i] <= 10:\n",
    "        mintues10flag.append(\"Yes\")\n",
    "    else:\n",
    "        mintues10flag.append(\"No\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    #if minutes[i] > 120:\n",
    "    #    mintues120flag.append(1)\n",
    "    #else:\n",
    "    #    mintues120flag.append(0)\n",
    "        \n",
    "    #if minutes[i] > 10:\n",
    "    #    greater10minutesflag.append(\"Yes\")\n",
    "    #else:\n",
    "    #    greater10minutesflag.append(\"No\")\n",
    "        \n",
    "        \n",
    "        \n",
    "print (len(mintues30flag))\n",
    "print (len(mintues20flag))\n",
    "print (len(mintues10flag))\n",
    "\n",
    "\n",
    "#print (len(mintues120flag))\n",
    "#print (len(greater10minutesflag))\n",
    "print (len(dl3))\n",
    "\n",
    "dl3[\"<=30 min\"] = mintues30flag\n",
    "dl3[\"<=20 min\"] = mintues20flag\n",
    "dl3[\"<=10 min\"] = mintues10flag\n",
    "\n",
    "#dl3[\">120 min\"] = mintues120flag\n",
    "#dl3[\">10 min\"] = greater10minutesflag\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12678471",
   "metadata": {},
   "source": [
    "### Create Apartment String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl3 = dl3.reset_index(drop=True)\n",
    "\n",
    "#line = \"071.04.008.F01.01A.KIT01\"\n",
    "#updated_line = '.'.join(line.split('.')[:-1])\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "updated_line = []\n",
    "\n",
    "for i in range(0, len(dl3)):\n",
    "    line = dl3[\"location\"][i]\n",
    "    linesplit = line.split(\".\")\n",
    "    \n",
    "    if len(linesplit) == 6:\n",
    "        a = '.'.join(line.split('.')[:-1])\n",
    "        #print (a)\n",
    "        updated_line.append(a)\n",
    "    else:\n",
    "        #print (line)\n",
    "        updated_line.append(line)\n",
    "\n",
    "print (len(dl3))\n",
    "print (len(updated_line))\n",
    "\n",
    "dl3[\"Apartment\"] = updated_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for c in desc:\n",
    "    d = set(dl3[c].tolist())\n",
    "    print (c)\n",
    "    print (d)\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16378d7f",
   "metadata": {},
   "source": [
    "### Calculate occurence of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb04dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl3[\"Percent No\"] = \"\"\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "dl3['HAVE YOU VERIFIED THE 5 ALIVE IN AREAS YOU WERE ABLE TO INSPECT. 5 ALIVE VERIFICATION'] = dl3['HAVE YOU VERIFIED THE 5 ALIVE IN AREAS YOU WERE ABLE TO INSPECT. 5 ALIVE VERIFICATION'].str.replace('Y', 'S')\n",
    "dl3['HAVE YOU VERIFIED THE 5 ALIVE IN AREAS YOU WERE ABLE TO INSPECT. 5 ALIVE VERIFICATION'] = dl3['HAVE YOU VERIFIED THE 5 ALIVE IN AREAS YOU WERE ABLE TO INSPECT. 5 ALIVE VERIFICATION'].str.replace('N', 'U')\n",
    "\n",
    "\n",
    "for c in desc:\n",
    "    dl3[c] = dl3[c].astype(str)\n",
    "\n",
    "percent_u = []\n",
    "percent_s = []\n",
    "percent_nan = []\n",
    "percent_cat = []\n",
    "\n",
    "\n",
    "for i in range(0, len(dl3)):\n",
    "#for i in range(0, 2):\n",
    "\n",
    "    count = []\n",
    "    for c in desc:\n",
    "        d = dl3[c][i]\n",
    "        count.append(d)\n",
    "    \n",
    "    #d = dl3[\"Frass Removal\"][i]\n",
    "    #count.append(d)\n",
    "    \n",
    "    #d = dl3[\"HEPA Vacuum\"][i]\n",
    "    #count.append(d)\n",
    "    \n",
    "    #d = dl3[\"Fill holes with excluder mesh or similar product\"][i]\n",
    "    #count.append(d)\n",
    "    \n",
    "    #d = dl3[\"Sealing\"][i]\n",
    "    #count.append(d)\n",
    "    \n",
    "    #d = dl3[\"Escutcheon Plate Installation\"][i]\n",
    "    #count.append(d)\n",
    "   \n",
    "    u = (count.count('U')/len(desc))\n",
    "    u = round(u, 3)\n",
    "    s = (count.count('S')/len(desc))\n",
    "    s = round(s, 3)\n",
    "    nan = (count.count('nan')/len(desc))\n",
    "    nan = round(nan, 3)\n",
    "    cat = (count.count('CAT')/len(desc))\n",
    "    cat = round(cat, 3)\n",
    "\n",
    " \n",
    "    percent_u.append(u)\n",
    "    percent_s.append(s)\n",
    "    percent_nan.append(nan)\n",
    "    percent_cat.append(cat)\n",
    "    \n",
    "\n",
    "print (len(dl3))   \n",
    "print (len(percent_u))   \n",
    "print (len(percent_s))   \n",
    "print (len(percent_nan))   \n",
    "print (len(percent_cat))   \n",
    "\n",
    " \n",
    "dl3[\"Percent U\"] = percent_u\n",
    "dl3[\"Percent S\"] = percent_s\n",
    "dl3[\"Percent nan\"] = percent_nan\n",
    "dl3[\"Percent CAT\"] = percent_cat\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d6e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl3.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd613954",
   "metadata": {},
   "source": [
    "### Convert Transaction Type to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "print (\"Convert transactions to dummies\")\n",
    "transaction_dummies = pd.get_dummies(dl3[\"transtype\"])\n",
    "\n",
    "\n",
    "#transaction_dummies[\"WORK\"] = transaction_dummies[\"WORK\"] + transaction_dummies[\"WORKWITHSEQ\"]\n",
    "\n",
    "#transaction_dummies = transaction_dummies.drop('WORKWITHSEQ', 1)\n",
    "\n",
    "transaction_dummies.to_csv ( path + \"test.csv\", index=False)\n",
    "\n",
    "print (len(transaction_dummies))\n",
    "print (len(dl3))\n",
    "\n",
    "dl4 = pd.concat([dl3, transaction_dummies], axis=1)\n",
    "\n",
    "print (len(dl4))\n",
    "\n",
    "\n",
    "dl4[\"INSPECTION\"] = dl4[\"INSPECTION\"].astype(str)\n",
    "dl4[\"INSPECTION\"] = dl4[\"INSPECTION\"].str.replace('True', '1')\n",
    "dl4[\"INSPECTION\"] = dl4[\"INSPECTION\"].str.replace('False', '0')\n",
    "\n",
    "dl4[\"NOBLDGACCESS\"] = dl4[\"NOBLDGACCESS\"].astype(str)\n",
    "dl4[\"NOBLDGACCESS\"] = dl4[\"NOBLDGACCESS\"].str.replace('True', '1')\n",
    "dl4[\"NOBLDGACCESS\"] = dl4[\"NOBLDGACCESS\"].str.replace('False', '0')\n",
    "\n",
    "dl4[\"RESNOTHOME\"] = dl4[\"RESNOTHOME\"].astype(str)\n",
    "dl4[\"RESNOTHOME\"] = dl4[\"RESNOTHOME\"].str.replace('True', '1')\n",
    "dl4[\"RESNOTHOME\"] = dl4[\"RESNOTHOME\"].str.replace('False', '0')\n",
    "\n",
    "dl4[\"RESREFUSED\"] = dl4[\"RESREFUSED\"].astype(str)\n",
    "dl4[\"RESREFUSED\"] = dl4[\"RESREFUSED\"].str.replace('True', '1')\n",
    "dl4[\"RESREFUSED\"] = dl4[\"RESREFUSED\"].str.replace('False', '0')\n",
    "\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adb8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963da6a4",
   "metadata": {},
   "source": [
    "### Remove Non-NYCHA Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "print (\"remove non nycha employees\")\n",
    "\n",
    "dn = pd.read_csv(path + \"7A Exterminators Group_Validation_Records as of 03-30-2023.csv\")\n",
    "\n",
    "dn[\"Badge #\"] = dn[\"Badge #\"].astype(str).map(str.strip)\n",
    "\n",
    "badge = dn[\"Badge #\"].tolist()\n",
    "\n",
    "\n",
    "for i in range(len(badge)):\n",
    "    #print (len(badge[i]))\n",
    "    \n",
    "    if len(badge[i]) == 2:\n",
    "        badge[i] = \"0000\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 3:\n",
    "        badge[i] = \"000\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 4:\n",
    "        badge[i] = \"00\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 5:\n",
    "        badge[i] = \"0\" + badge[i]\n",
    "        \n",
    "dn[\"Badge #\"] = badge\n",
    "\n",
    "dn[\"Employee Type\"] = \"NYCHA Employee\"\n",
    "\n",
    "dnDic = dn.set_index('Badge #')['Employee Type'].to_dict()\n",
    "\n",
    "\n",
    "dl4[\"laborcode\"] = dl4[\"laborcode\"].astype(str).map(str.strip)\n",
    "\n",
    "dl4[\"Employee Type\"] = dl4[\"laborcode\"].map(dnDic)\n",
    "\n",
    "dl4[\"Employee Type\"] = dl4[\"Employee Type\"].fillna(\"Other\")\n",
    "\n",
    "print (\"len before drop\", len(dl4))\n",
    "\n",
    "dl4 = dl4[dl4[\"Employee Type\"] == \"NYCHA Employee\"]\n",
    "\n",
    "print (\"len after drop\", len(dl4))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "\n",
    "dl4 = dl4.reset_index(drop=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfecb35",
   "metadata": {},
   "source": [
    "### Change Field Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl4 = dl3.copy()\n",
    "\n",
    "dl4[\"Finish Date\"] = dl4[\"finishdatetime\"].apply(lambda x: x.date())\n",
    "dl4[\"Start Date\"] = dl4[\"startdatetime\"].apply(lambda x: x.date())\n",
    "dl4 = dl4.rename(columns={'problemcode': 'Problem Code'})\n",
    "dl4 = dl4.rename(columns={'failurecode': 'Failure Code'})\n",
    "dl4 = dl4.rename(columns={'ownergroup': 'Owner Group'})\n",
    "dl4 = dl4.rename(columns={'transtype': 'Transaction Type'})\n",
    "dl4 = dl4.rename(columns={'status': 'Status'})\n",
    "dl4 = dl4.rename(columns={'displayname': 'Name'})\n",
    "dl4 = dl4.rename(columns={'department': 'Department'})\n",
    "dl4 = dl4.rename(columns={'title': 'Title'})\n",
    "dl4 = dl4.rename(columns={'zzhrtitle': 'HR Title'})\n",
    "dl4 = dl4.rename(columns={'zzcraft': 'Craft'})\n",
    "dl4 = dl4.rename(columns={'Enterdate': 'Enter Date'})\n",
    "\n",
    "\n",
    "dl4[\"Count\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38cd24",
   "metadata": {},
   "source": [
    "### Calculate Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transtype = list(set(dl4[\"Transaction Type\"].tolist() ) )\n",
    "#transtype\n",
    "#transtype = list(set(dl4[\"Transaction Type 2\"].tolist() ) )\n",
    "#transtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aff77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "#dl5 = dl4[\"Name\", \"Transaction Type\", \"Minutes\"]\n",
    "\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type\"]\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('WORKWITHSEQ', 'WORK')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('NOBLDGACCESS', 'NO ACCESS')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('RESNOTHOME', 'NO ACCESS')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('RESREFUSED', 'NO ACCESS')\n",
    "\n",
    "transtype = list(set(dl4[\"Transaction Type 2\"].tolist() ) )\n",
    "\n",
    "print (\"WORK\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"WORK\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"WORK\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn1 = qn.copy()\n",
    "\n",
    "\n",
    "\n",
    "print (\"NO ACCESS\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"NO ACCESS\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"NO ACCESS\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn2 = qn.copy()\n",
    "\n",
    "\n",
    "\n",
    "print (\"UNFOUNDED\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"NO ACCESS\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"UNFOUNDED\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn3 = qn.copy()\n",
    "\n",
    "\n",
    "frames = [qn1, qn2, qn3]\n",
    "result = pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b08237",
   "metadata": {},
   "source": [
    "### Calculate Number of People work On a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "print (\"Calculate number of people\")\n",
    "\n",
    "dol = dl4[[\"location\", \"Finish Date\", \"Name\", \"startdatetime\", \"finishdatetime\", \"Transaction Type\" ] ]\n",
    "\n",
    "dol = dol.sort_values(by = 'location', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dol[\"Finish Date\"] = dol[\"Finish Date\"].astype(str).map(str.strip)\n",
    "dol[\"LocationDate\"] = dol[\"location\"] + \" \" + dol[\"Finish Date\"]\n",
    "\n",
    "locations = sorted(set(dol[\"location\"].tolist() ))\n",
    "\n",
    "#print (len(dol))\n",
    "#dol = dol.drop_duplicates([\"location\", \"Finish Date\", \"Name\"]).reset_index(drop=True)\n",
    "#print (len(dol))\n",
    "\n",
    "numberList = []\n",
    "nameList = []\n",
    "\n",
    "for i in range(0, len(locations)):\n",
    "#for i in range(0, 1000):\n",
    "\n",
    "    l = locations[i]\n",
    "    \n",
    "    #print (l)\n",
    "    #print (l)\n",
    "    dol2 = dol[dol[\"location\"] == l]\n",
    "    \n",
    "    dol2 = dol2.sort_values(by = 'Finish Date', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    #print (dol2)\n",
    "    #print(\"******************\")\n",
    "    \n",
    "    \n",
    "    d = sorted(set(dol2[\"Finish Date\"].tolist() ))\n",
    "    \n",
    "    #print (len(d))\n",
    "    \n",
    "    for j in range(0, len(d)):\n",
    "        dol3 = dol2[dol2[\"Finish Date\"] == d[j]].reset_index(drop=True)\n",
    "        dol3[\"Name\"] = dol3[\"Name\"].astype(str)\n",
    "        names = sorted(set(dol3[\"Name\"].tolist() ))\n",
    "        \n",
    "        if (len(dol3) > 1 and len(names)>1):\n",
    "            #print (dol3)\n",
    "            #print(\"******************\")\n",
    "            #numberDic = {dol3[\"LocationDate\"][0]}\n",
    "            #numberDic[dol3[\"LocationDate\"][0]] = len(names)\n",
    "            numberList.append([dol3[\"LocationDate\"][0], len(names)])\n",
    "            nameList.append([dol3[\"LocationDate\"][0], names])\n",
    "\n",
    "\n",
    "    #print(dol2)\n",
    "    #print(\"******************\")\n",
    "    \n",
    "print (len(numberList))\n",
    "print (len(nameList))\n",
    "print (\"DONE\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0293a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8a5e4",
   "metadata": {},
   "source": [
    "Create Dictionaries and Combine with Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print (\"Insert number on the job\")\n",
    "numberDict = {}\n",
    "for l2 in numberList:\n",
    "    numberDict[l2[0]] = l2[1]\n",
    "    \n",
    "nameDict = {}\n",
    "for l2 in nameList:\n",
    "    nameDict[l2[0]] = l2[1]\n",
    "    \n",
    "dl4[\"Finish Date\"] = dl4[\"Finish Date\"].astype(str).map(str.strip)\n",
    "dl4[\"LocationDate\"] = dl4[\"location\"] + \" \" + dl4[\"Finish Date\"]\n",
    "\n",
    "dl4[\"Number on Job\"] = dl4[\"LocationDate\"].map(numberDict)\n",
    "dl4[\"Employees on Job > 1\"] = dl4[\"LocationDate\"].map(nameDict)\n",
    "\n",
    "#dl4 = dl4.drop('Employees on Job', 1)\n",
    "\n",
    "dl4[\"Number on Job\"] = dl4[\"Number on Job\"].fillna(1)\n",
    "\n",
    "print (\"DONE\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = dl4.columns\n",
    "#cols = sorted(cols)\n",
    "#cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dol.to_csv(path + \"test_num_people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d296a9",
   "metadata": {},
   "source": [
    "### Calculate Work Time per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "    \n",
    "    # Radius of the Earth in miles\n",
    "    earth_radius = 3959.0  # Mean radius in miles\n",
    "    \n",
    "    # Calculate the differences in coordinates\n",
    "    delta_lat = lat2_rad - lat1_rad\n",
    "    delta_lon = lon2_rad - lon1_rad\n",
    "    \n",
    "    # Haversine formula\n",
    "    a = math.sin(delta_lat / 2) ** 2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(delta_lon / 2) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = earth_radius * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "# Example coordinates: New York City and Los Angeles\n",
    "lat1= 40.713196\n",
    "lon1= -73.98156857\n",
    "\n",
    "lat2= 40.79802487\n",
    "lon2= -73.94695356\n",
    "\n",
    "distance = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "print(f\"Distance between points: {distance:.2f} miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de63db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4[\"Transaction Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathout = \"\"\n",
    "\n",
    "print (len(dl4))\n",
    "dl4[\"Name\"] = dl4[\"Name\"].astype(str)\n",
    "dl4 = dl4[dl4[\"Name\"] != \"None\"]\n",
    "print (len(dl4))\n",
    "\n",
    "dl4[\"Start Date\"] = dl4[\"startdatetime\"].apply(lambda x: x.date())\n",
    "dl4[\"Start Time\"] = dl4[\"startdatetime\"]\n",
    "dl4[\"Finish Time\"] = dl4[\"finishdatetime\"]\n",
    "\n",
    "\n",
    "#dl4[\"Development\"] = dl4['location'].str.split(\".\").str[0]\n",
    "#dl4[\"Development\"] = dl4[\"Development\"].map(str.strip)\n",
    "\n",
    "\n",
    "dl5 = dl4[[\"Name\", \"Start Date\", \"Finish Date\", \"Start Time\", \"Finish Time\", \"Minutes\", \"development_name\", \"lat\", \"lon\",\n",
    "          \"Transaction Type\"]]\n",
    "\n",
    "dl5 = dl5[dl5[\"Transaction Type\"] == \"INSPECTION\"].reset_index(drop=True)\n",
    "\n",
    "dl5 = dl5.sort_values(by = 'Start Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dl5[\"Start Date\"] = dl5[\"Start Date\"].astype(str).map(str.strip)\n",
    "dl5[\"Finish Date\"] = dl5[\"Finish Date\"].astype(str).map(str.strip)\n",
    "\n",
    "dates = sorted(list(set(dl5[\"Start Date\"].tolist() )))\n",
    "\n",
    "len(dates)\n",
    "\n",
    "dt = pd.DataFrame(columns=('Name', 'Start Date', 'Finish Date', 'Day Start Time', 'Day End Time', \n",
    "                           'Number of Jobs', 'Minutes Worked', 'Developments', 'Distance Traveled (mi)'))\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(dates)):\n",
    "#for i in range(0, 1):\n",
    "\n",
    "    #print(i)\n",
    "    dl6 = dl5[dl5[\"Start Date\"] == dates[i]]\n",
    "    dl6 = dl6[dl6[\"Finish Date\"] == dates[i]]\n",
    "    dl6 = dl6.reset_index(drop=True)\n",
    "    \n",
    "    names = list(set(dl6[\"Name\"].tolist() ))\n",
    "    \n",
    "    for j in range(0, len(names)):\n",
    "    #for j in range(0, 1):\n",
    "        \n",
    "        distlist = []\n",
    "    \n",
    "        dl7 = dl6[dl6[\"Name\"] == names[j]]\n",
    "        \n",
    "        dl7 = dl7.sort_values(by = 'Start Time', ascending=True).reset_index(drop=True)\n",
    "        \n",
    "        developments = sorted(list(set(dl7[\"development_name\"].tolist() )) )\n",
    "        lat = dl7[\"lat\"].tolist()\n",
    "        lon = dl7[\"lon\"].tolist()\n",
    "        \n",
    "        for k in range(0, len(lat)-1):\n",
    "            distance = haversine_distance(lat[k], lon[k], lat[k+1], lon[k+1])\n",
    "            distlist.append(distance)\n",
    "            #print (len(distlist))\n",
    "            #print (distance)\n",
    "            #print ()\n",
    "\n",
    "        \n",
    "        \n",
    "        totalMinWorked = dl7[\"Minutes\"].sum()\n",
    "        \n",
    "        starttime = sorted(dl7[\"Start Time\"].tolist() )\n",
    "        endtime = sorted(dl7[\"Finish Time\"].tolist(),  reverse=True )\n",
    "\n",
    "\n",
    "        start = starttime[0]\n",
    "        end = endtime[0]\n",
    "        \n",
    "        #print (start)\n",
    "        #print (end)\n",
    "        \n",
    "        sumdistlist = sum(distlist)\n",
    "        \n",
    "        dt.loc[j] = [names[j],dates[i],dates[i], start, end, len(dl7), totalMinWorked, str(developments), sumdistlist]\n",
    "        \n",
    "        fileout = \"work_time\" + str(i) + \".csv\"\n",
    "\n",
    "        dt.to_csv(pathout + fileout, index=False)\n",
    "\n",
    "\n",
    "    #all_data = all_data.append(dt,ignore_index=False).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "#all_data = all_data.sort_values(by = 'Start Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#all_data['Hours Worked'] = (all_data['Day End Time'] - all_data['Day Start Time']).dt.total_seconds()/3600\n",
    "#all_data['Minutes Worked'] = (all_data['Day End Time'] - all_data['Day Start Time']).dt.total_seconds()/60\n",
    "\n",
    "#all_data['Day Start Time'] = all_data['Day Start Time'].apply( lambda d : d.time() )\n",
    "\n",
    "#all_data['Day End Time'] = all_data['Day End Time'].apply( lambda d : d.time() )\n",
    "\n",
    "#all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "#all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1840fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abeee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print (\"Read csv files back into a data frame\")\n",
    "\n",
    "# Get a list of all CSV file paths in a directory\n",
    "csv_files = glob.glob( '*.csv')\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    dt = pd.read_csv(file)\n",
    "    dataframes.append(dt)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "all_data = final_df.copy()\n",
    "\n",
    "pathread = ''\n",
    "\n",
    "# Get a list of all CSV file paths in the directory\n",
    "csv_files = glob.glob(os.path.join(pathread, '*.csv'))\n",
    "\n",
    "# Loop through each CSV file and delete it\n",
    "for file_path in csv_files:\n",
    "    os.remove(file_path)\n",
    "\n",
    "print(\"CSV files deleted successfully.\")\n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53b4ffc",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6aa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Hours Worked\"] = all_data[\"Minutes Worked\"]/60.0\n",
    "all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "all_data['Hours Worked'] = \"\"\n",
    "#all_data['Minutes Worked'] = \"\"\n",
    "\n",
    "for i in range(0, len(all_data)):\n",
    "    d = all_data[\"Day End Time\"][i] - all_data[\"Day Start Time\"][i]\n",
    "\n",
    "    diff = d.seconds\n",
    "\n",
    "    diff = int(diff)\n",
    "    \n",
    "    all_data['Hours Worked'][i] = diff/3600.0\n",
    "    #all_data['Minutes Worked'][i] = diff/60.0\n",
    "\n",
    "\n",
    "    #print (diff)\n",
    "    \n",
    "all_data = all_data.sort_values(by = 'Hours Worked', ascending=False).reset_index(drop=True)\n",
    "\n",
    "all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b331a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2 = all_data.drop_duplicates(subset=['Name', 'Day Start Time', 'Day End Time', 'Number of Jobs']).reset_index(drop=True)\n",
    "print (len(all_data))\n",
    "print (len(all_data2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893c069",
   "metadata": {},
   "source": [
    "Outside Normal Work Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62185510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data2[\"Day End Time\"][0].hour\n",
    "\n",
    "all_data2[\"Day Start Time\"] = pd.to_datetime(all_data2[\"Day Start Time\"])\n",
    "all_data2[\"Day End Time\"] = pd.to_datetime(all_data2[\"Day End Time\"])\n",
    "\n",
    "all_data2[\"Outside Normal Work Hours\"] = \"No\"\n",
    "\n",
    "for i in range(0, len(all_data2)):\n",
    "    if (all_data2[\"Day Start Time\"][i].hour <= 7 or all_data2[\"Day End Time\"][i].hour >= 21):\n",
    "        all_data2[\"Outside Normal Work Hours\"][i] = \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6cc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2[\"Day Start Time\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d122c3e",
   "metadata": {},
   "source": [
    "### Mode: Start and End Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20651324",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2[\"Day Start Time\"][0].hour\n",
    "all_data2[\"Start Hour\"] = \"\"\n",
    "all_data2[\"End Hour\"] = \"\"\n",
    "\n",
    "for i in range(0, len(all_data2)):\n",
    "    all_data2[\"Start Hour\"][i] =  all_data2[\"Day Start Time\"][i].hour\n",
    "    all_data2[\"End Hour\"][i] =  all_data2[\"Day End Time\"][i].hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sorted(list(set(all_data2[\"Name\"].tolist()  )))\n",
    "\n",
    "qnhours = pd.DataFrame(columns=('Emplpoyee Name', 'Mode Start Time', 'Count of Start Mode', \n",
    "                                'Mode End Time', 'Count of End Mode', 'Total Number of Days Worked'))\n",
    "\n",
    "\n",
    "#dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "all_data2[\"Start Hour Cat\"] = all_data2[\"Start Hour\"].astype(str)\n",
    "all_data2[\"End Hour Cat\"] = all_data2[\"End Hour\"].astype(str)\n",
    "\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    all_data3 = all_data2[all_data2[\"Name\"] == n].reset_index(drop=True)\n",
    "    all_data3[\"Count\"] = 1\n",
    "    \n",
    "    #start time mode\n",
    "    all_data3G = all_data3[[\"Start Hour Cat\", \"Count\"]]\n",
    "    all_data3G = all_data3G.groupby(['Start Hour Cat']).sum()\n",
    "    all_data3G = all_data3G.add_suffix('').reset_index()\n",
    "    all_data3G = all_data3G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "    starthourmode = all_data3G[\"Start Hour Cat\"][0]\n",
    "    starthourmodecount = all_data3G[\"Count\"][0]\n",
    "    \n",
    "    #end time mode\n",
    "    all_data3G = all_data3[[\"End Hour Cat\", \"Count\"]]\n",
    "    all_data3G = all_data3G.groupby(['End Hour Cat']).sum()\n",
    "    all_data3G = all_data3G.add_suffix('').reset_index()\n",
    "    all_data3G = all_data3G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "    endhourmode = all_data3G[\"End Hour Cat\"][0]\n",
    "    endhourmodecount = all_data3G[\"Count\"][0]\n",
    "    \n",
    "        \n",
    "    if len(all_data3) > 0:\n",
    "        qnhours.loc[i] = [n,starthourmode, starthourmodecount,endhourmode,endhourmodecount, len(all_data3)]\n",
    "\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Count of Start Mode\"]/qnhours[\"Total Number of Days Worked\"]\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Start Mode Relative Frequency\"].astype(float)\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Start Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"Count of End Mode\"]/qnhours[\"Total Number of Days Worked\"]\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"End Mode Relative Frequency\"].astype(float)\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"End Mode Relative Frequency\"].round(2)\n",
    "\n",
    "#qn1 = qn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518c8f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnhours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa1aeb",
   "metadata": {},
   "source": [
    "### Calculate the Days of the Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = monday, 1=tuesday, 2=wednesday, 3=thursday, 4=friday, 5=saturday, 6=sunday\n",
    "dl4[\"Day\"] = dl4['Finish Time'].dt.dayofweek\n",
    "dl4[\"Day\"] = dl4[\"Day\"].astype(str).map(str.strip)\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('0', 'Monday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('1', 'Tuesday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('2', 'Wednesday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('3', 'Thursday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('4', 'Friday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('5', 'Saturday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('6', 'Sunday')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f47722",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4 = dl4.reset_index(drop=True)\n",
    "\n",
    "\n",
    "dl4['Finish Time 2'] = dl4[\"Finish Time\"].apply( lambda d : d.time() )\n",
    "\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].astype(str).map(str.strip)\n",
    "\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].str.split(\":\").str[0]\n",
    "\n",
    "\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].astype(int)\n",
    "\n",
    "dl4[\"Work After 4pm\"] = \"No\"\n",
    "\n",
    "for i in range(0, len(dl4)):\n",
    "    if dl4['Finish Time 2'][i] >= 16:\n",
    "        dl4[\"Work After 4pm\"][i] = \"Yes\"\n",
    "\n",
    "\n",
    "#if dl4[\"Finish Time 2\"][0] > pd.datetime('13:10:00'):\n",
    "#    print (\"hey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3cc462",
   "metadata": {},
   "source": [
    "### Create Dummes for Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1143220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "a = dl4[\"Frass Removal\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Education Literature\"] = dummies \n",
    "\n",
    "\n",
    "\n",
    "a = dl4[\"Frass Removal\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Frass\"] = dummies \n",
    "\n",
    "\n",
    "a = dl4[\"HEPA Vacuum\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"HEPA\"] = dummies\n",
    "\n",
    "\n",
    "a = dl4[\"Fill holes with excluder mesh or similar product\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Exluder mesh\"] = dummies       \n",
    "\n",
    "\n",
    "a = dl4[\"Sealing\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Seal\"] = dummies       \n",
    "\n",
    "a = dl4[\"Escutcheon Plate Installation\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)      \n",
    "dl4[\"Escutcheon Plate\"] = dummies       \n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737fd52",
   "metadata": {},
   "source": [
    "### Create Apartment and Public Space Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a70cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "locationlist = dl4[\"location\"].tolist()\n",
    "workspace = []\n",
    "for i in range(0, len(dl4)):\n",
    "    a = locationlist[i]\n",
    "    a = a.split(\".\")\n",
    "    #print (a)\n",
    "    \n",
    "    if len(a) < 5:\n",
    "        workspace.append(\"Public Space\")\n",
    "    else:\n",
    "        workspace.append(\"Apartment\")\n",
    "        \n",
    "print (len(dl4))\n",
    "print (len(workspace))\n",
    "    \n",
    "dl4[\"Work Space Type\"] =   workspace  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0602be",
   "metadata": {},
   "source": [
    "### Create Hour Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl4[\"Hour of Day\"] = dl4[\"Finish Time\"].hour\n",
    "\n",
    "hours = dl4[\"Finish Time\"].tolist()\n",
    "\n",
    "hourofday = []\n",
    "\n",
    "for i in range(0, len(hours)):\n",
    "    #print (hours[i])\n",
    "    \n",
    "    a = hours[i].hour\n",
    "    \n",
    "    hourofday.append(a)\n",
    "    \n",
    "print (len(hourofday))\n",
    "print (len(dl4))\n",
    "\n",
    "dl4[\"Hour of Day\"] = hourofday\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b576a67",
   "metadata": {},
   "source": [
    "### Create NYCHA employee field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "dp = pd.read_csv(path + \"Pest Management Routes as of 1 31 23 CORRECTED.csv\")\n",
    "dp[\"Name\"] = dp[\"Name\"].astype(str).map(str.upper).map(str.strip)\n",
    "dp[\"Last Name\"] = dp[\"Name\"] .str.split(\",\").str[0].map(str.strip)\n",
    "dp[\"First Name\"] = dp[\"Name\"] .str.split(\",\").str[1].map(str.strip)\n",
    "\n",
    "dp[\"Last Name\"] = dp[\"Last Name\"].map(str.strip)\n",
    "dp[\"First Name\"] = dp[\"First Name\"].map(str.strip)\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"First Name\"] + \" \" + dp[\"Last Name\"]\n",
    "\n",
    "dp[\"NYCHA Employee\"] = \"NYCHA Employee (1_31_23)\"\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].map(str.strip)\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('AGATHA DESVIGNES-MCKAIN', 'AGATHA DESVIGNES MCKAIN')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('ALVEN LAKE', 'ALVIN LAKE')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('BRIAN JEFFRIES', 'BRIAN JEFFERIES')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('CELESTINE R PAYNE', 'CELESTINE PAYNE')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('DIEDRA EPHRAIM', 'DEIDRA EPHRAIM')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('DIOGENES UMANZAR', 'DIOGENES UMANZOR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('GEOVANI DORSEY', 'GEOVANNIE DORSEY')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('HERIBERTO CANTRES', 'HERIBERTO CANTES')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('JEMEEL TUCKER', 'JAMEEL TUCKER')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('JOSEPH UPSUR', 'JOSEPH UPSHUR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LAYR DORZIN', 'LAYR DORZIN, JR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LENAIR DANIELS', 'LENAIR DANIEL')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LORRAINE LOWERY- CLARK', 'LORRAINE LOWERY-CLARK')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('MATTEW MARTINEZ', 'MATTHEW MARTINEZ')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('NUDUKA OKORO', 'NDUKA OKORO')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('OLUYINKA ODUMNBAKU', 'OLUYINKA ODUNMBAKU')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SALVATORE CASTELLENO', 'SALVATORE CASTELLANO')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SHERIF RASHID', 'SHAREEF RASHID')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SHANICE CALLWOOD', 'SHAUNICE CALLWOOD')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SOLOMON SOOKOO', 'SOLOMAN SOOKOO')\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('VICAS FRANCIS', 'VICKAS FRANCIS')\n",
    "\n",
    "\n",
    "dpDic = dp.set_index('Full Name')['NYCHA Employee'].to_dict()\n",
    "\n",
    "dpList = dp[\"Full Name\"].tolist()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "dln = dl4[[\"Name\"]]\n",
    "dln[\"Name\"] = dln[\"Name\"].astype(str).map(str.upper).map(str.strip)\n",
    "dln = dln.drop_duplicates(['Name']).reset_index(drop=True)\n",
    "\n",
    "dln[\"NYCHA Employee\"] = dln[\"Name\"].map(dpDic)\n",
    "\n",
    "dln = dln.sort_values(by = 'Name', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dlnList = dln[\"Name\"].tolist()\n",
    "\n",
    "#dln.to_csv(path + \"test_names.csv\", index=False)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def fuzzy_match(string1, string2):\n",
    "    \n",
    "    #Compares two strings using fuzzy matching and returns a score between 0 and 100.\n",
    "\n",
    "    return fuzz.ratio(string1, string2)\n",
    "\n",
    "dln[\"NYCHA Employee\"] = dln[\"NYCHA Employee\"].astype(str)\n",
    "dln[\"Fuzzy Name Closest Match\"] = \"\"\n",
    "dln[\"Fuzzy Score\"] = \"\"\n",
    "\n",
    "for i in range(0, len(dln)):\n",
    "    if dln[\"NYCHA Employee\"][i]=='nan' :\n",
    "        n = dln[\"Name\"][i]\n",
    "        #print (n)\n",
    "        \n",
    "        namematch = []\n",
    "\n",
    "        for j in range(0, len(dpList)):\n",
    "            #print (dpList[j], fuzzy_match(n, dpList[j]))\n",
    "            namematch.append([dpList[j], fuzzy_match(n, dpList[j])])\n",
    "            \n",
    "            namematch = sorted(namematch, key=itemgetter(1), reverse=True)\n",
    "\n",
    "        dln[\"Fuzzy Name Closest Match\"][i] = namematch[0][0]\n",
    "        dln[\"Fuzzy Score\"][i] = namematch[0][1]\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dln.to_csv(path + \"test_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6ed7a",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b29262",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2.to_csv(path + \"Work Time Analytics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb001241",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnhours.to_csv(path + \"Start and End Time Modes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da277225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.to_csv(path + \"Time Mode and Employee Names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4.to_csv(path + \"Apartment Inspection Labor Transactions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1959e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl4.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "numinsp = list(set(dl4[\"Name\"].tolist() ))\n",
    "print (len(numinsp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b1d7c",
   "metadata": {},
   "source": [
    "# Calculate Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d7d145",
   "metadata": {},
   "source": [
    "### Minutes worked per inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data3 = all_data2.copy()\n",
    "\n",
    "all_data3 = all_data3[[\"Name\", \"Number of Jobs\", \"Minutes Worked\"]]\n",
    "\n",
    "all_data3 = all_data3.sort_values(by = 'Minutes Worked', ascending=False).reset_index(drop=True)\n",
    "\n",
    "all_data3G = all_data3.groupby(['Name']).sum()\n",
    "\n",
    "all_data3G = all_data3G.add_suffix('').reset_index()\n",
    "\n",
    "\n",
    "\n",
    "all_data3G[\"Avg Min Inspection\"] = all_data3G[\"Minutes Worked\"]/all_data3G[\"Number of Jobs\"]\n",
    "\n",
    "#all_data3G = all_data3G.sort_values(by = 'Avg Min Inspection', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "q1 = all_data3G['Number of Jobs'].quantile(0.25)  # First quartile (25th percentile)\n",
    "q2 = all_data3G['Number of Jobs'].quantile(0.50)  # First quartile (25th percentile)\n",
    "q3 = all_data3G['Number of Jobs'].quantile(0.75)  # First quartile (25th percentile)\n",
    "q4 = all_data3G['Number of Jobs'].quantile(1.00)  # First quartile (25th percentile)\n",
    "\n",
    "print (\"q1\", q1)\n",
    "print (\"q2\", q2)\n",
    "print (\"q3\", q3)\n",
    "print (\"q4\", q4)\n",
    "\n",
    "all_data3G = all_data3G.sort_values(by = 'Number of Jobs', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print (len(all_data3G))\n",
    "all_data3G = all_data3G[all_data3G[\"Number of Jobs\"] > 100]\n",
    "print (len(all_data3G))\n",
    "\n",
    "print (\"Number of Inspections\")\n",
    "print (\"Avg num inspections\", all_data3G[\"Number of Jobs\"].mean())\n",
    "print (\"Median num inspections\", all_data3G[\"Number of Jobs\"].median())\n",
    "print (\"Std num inspections\", all_data3G[\"Number of Jobs\"].std())\n",
    "\n",
    "print()\n",
    "print (\"time per inspection\")\n",
    "print (\"Avg min per inspection\", all_data3G[\"Avg Min Inspection\"].mean())\n",
    "print (\"Median per inspections\", all_data3G[\"Avg Min Inspection\"].median())\n",
    "print (\"Std dev min per inspection\", all_data3G[\"Avg Min Inspection\"].std())\n",
    "\n",
    "\n",
    "all_data3G = all_data3G.sort_values(by = 'Avg Min Inspection', ascending=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205bdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data3G[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb485062",
   "metadata": {},
   "source": [
    "### Percent S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3410d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl5 = dl4[[\"Name\", \"Percent S\"]]\n",
    "\n",
    "dl5[\"Count\"] = 1\n",
    "\n",
    "#dl5G = dl5.groupby(['Name','Percent S', 'Count']).mean()\n",
    "\n",
    "dl5G = (dl5.groupby('Name').agg({'Percent S':'mean', 'Count': 'sum'}).rename(columns={'Count':'Count'}) )\n",
    "\n",
    "\n",
    "dl5G = dl5G.add_suffix('').reset_index()\n",
    "\n",
    "print (len(dl5G))\n",
    "dl5G = dl5G[dl5G[\"Count\"] > 100]\n",
    "print (len(dl5G))\n",
    "\n",
    "\n",
    "dl5G = dl5G.sort_values(by = 'Percent S', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print()\n",
    "print (\"time per inspection\")\n",
    "print (\"Avg percent S\", dl5G[\"Percent S\"].mean())\n",
    "print (\"Median percent S\", dl5G[\"Percent S\"].median())\n",
    "print (\"Std dev percent S\", dl5G[\"Percent S\"].std())\n",
    "\n",
    "\n",
    "q1 = dl5G[\"Percent S\"].quantile(0.25)  # First quartile (25th percentile)\n",
    "q2 = dl5G[\"Percent S\"].quantile(0.50)  # First quartile (25th percentile)\n",
    "q3 = dl5G[\"Percent S\"].quantile(0.75)  # First quartile (25th percentile)\n",
    "q4 = dl5G[\"Percent S\"].quantile(1.00)  # First quartile (25th percentile)\n",
    "\n",
    "print (\"q1\", q1)\n",
    "print (\"q2\", q2)\n",
    "print (\"q3\", q3)\n",
    "print (\"q4\", q4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b69b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Percent S and Avg min per inspection\")\n",
    "\n",
    "dl5 = dl4.copy()\n",
    "\n",
    "dl5[\"Count\"] = 1\n",
    "\n",
    "dl5[\"INSPECTION\"] = dl5[\"INSPECTION\"].astype(int)\n",
    "dl5[\"RESNOTHOME\"] = dl5[\"RESNOTHOME\"].astype(int)\n",
    "\n",
    "dl5 = dl5[[\"Name\", \"Minutes\", \"Percent S\", \"INSPECTION\", \"Count\"]]\n",
    "\n",
    "print (len(dl5))\n",
    "dl5 = dl5[dl5[\"INSPECTION\"] == 1]\n",
    "print (len(dl5))\n",
    "\n",
    "dl5G = (dl5.groupby('Name').agg({'Percent S':'mean', 'Count': 'sum', 'Minutes':'sum', 'INSPECTION':'sum'}).rename(columns={'Count':'Count'}) )\n",
    "\n",
    "dl5G = dl5G.add_suffix('').reset_index()\n",
    "\n",
    "\n",
    "print (len(dl5G))\n",
    "dl5G = dl5G[dl5G[\"Count\"] > 100]\n",
    "print (len(dl5G))\n",
    "\n",
    "dl5G[\"Avg min inspection\"] = dl5G[\"Minutes\"]/dl5G[\"Count\"]\n",
    "\n",
    "dl5G = dl5G.sort_values(by = 'Avg min inspection', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#dl6 = dl4.copy()\n",
    "#dl6[\"Count\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f438e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl5G.to_csv(path + \"Bad Actor List.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07972fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4.dtypes[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536080fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4[\"INSPECTION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81784e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
